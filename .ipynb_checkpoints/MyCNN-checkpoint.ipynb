{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Dense, Conv2D, Flatten, ZeroPadding2D, BatchNormalization\n",
    "from keras.layers import MaxPooling2D, AveragePooling2D, Dropout, GlobalMaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array\n",
    "from random import seed \n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Body_classifier_project\\ImgCNN\n"
     ]
    }
   ],
   "source": [
    "directory = os.path.abspath('ImgCNN')\n",
    "print(directory)\n",
    "directory_train = os.path.join(directory, 'Train')\n",
    "directory_test = os.path.join(directory, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "i = 0\n",
    "category = ['Skinny', 'Skinny Fat']\n",
    "for c in category:\n",
    "    path = os.path.join(directory_train, c)\n",
    "    for file in os.listdir(path):\n",
    "        classes = category.index(c)\n",
    "        Y.append(classes)\n",
    "        img_path = os.path.join(path, file)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_r = cv2.resize(img, (224, 224))\n",
    "        X.append(img_r)\n",
    "        \n",
    "X_train = np.array(X)\n",
    "Y_train = np.array(Y)\n",
    "Y_train = to_categorical(Y_train)\n",
    "cv2.imshow(\"New Image\", X_train[35])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "m = X_train.shape[0]\n",
    "permutation = list(np.random.permutation(m))\n",
    "X = X_train[permutation, :]\n",
    "Y = Y_train[permutation, :]\n",
    "X_train = X\n",
    "X_train = X_train.reshape((59, 224, 224, 1))\n",
    "Y_train = Y\n",
    "cv2.imshow(\"new img\", X_train[35])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def My_model(input_shape):\n",
    "    X_input = Input(input_shape)\n",
    "    X = Dropout(rate = 0.2, seed = 1)(X_input)\n",
    "    X = Conv2D(50, (11, 11), strides = (4, 4), name = 'conv_0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    #X = Dropout(rate = 0.2, seed = 1)(X)\n",
    "    X = MaxPooling2D((3, 3), strides = (2, 2), name = 'mp_0')(X)\n",
    "    X = Conv2D(80, (5, 5), strides = (1, 1), padding = 'same', name = 'conv_1')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    #X = Dropout(rate = 0.2, seed = 1)(X)\n",
    "    X = MaxPooling2D((3, 3), strides = (2, 2), name = 'mp_1')(X)\n",
    "    X = Conv2D(90, (3, 3), strides = (1, 1), padding = 'same', name = 'conv_2')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(rate = 0.2, seed = 1)(X)\n",
    "    X = Conv2D(100, (3, 3), strides = (1, 1), padding = 'same', name = 'conv_3')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_3')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(rate = 0.3, seed = 1)(X)\n",
    "    X = Conv2D(100, (3, 3), strides = (1, 1), padding = 'same', name = 'conv_4')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_4')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(rate = 0.3, seed = 1)(X)\n",
    "    X = MaxPooling2D((3, 3), strides = (2, 2), name = 'mp_2')(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(100, activation = 'relu', name = 'fc_1')(X)\n",
    "    X = Dropout(rate = 0.2, seed = 1)(X)\n",
    "    X = Dense(50, activation = 'relu', name = 'fc_2')(X)\n",
    "    #X = Dropout(rate = 0.1, seed = 1)(X)\n",
    "    X = Dense(20, activation = 'sigmoid', name = 'fc_3')(X)\n",
    "    X = Dense(2, activation = 'softmax', name = 'output_layer')(X)\n",
    "    model = Model(inputs = X_input, outputs = X, name = 'MyCNN')\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 1)\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[1:])\n",
    "mymodel = My_model(X_train.shape[1:])\n",
    "mymodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center = True,\n",
    "    featurewise_std_normalization = True,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    vertical_flip = False,\n",
    "    horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 6s 97ms/step - loss: 0.7625 - acc: 0.5593\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 3s 43ms/step - loss: 0.7071 - acc: 0.5763\n",
      "Epoch 1\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.6938 - acc: 0.5424\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.6853 - acc: 0.5254\n",
      "Epoch 2\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.7081 - acc: 0.4746\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.6906 - acc: 0.5593\n",
      "Epoch 3\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.6828 - acc: 0.5424\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 0.6710 - acc: 0.4915\n",
      "Epoch 4\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.5922 - acc: 0.7627\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.6401 - acc: 0.6271\n",
      "Epoch 5\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.6513 - acc: 0.6271\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.6673 - acc: 0.6271\n",
      "Epoch 6\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.6137 - acc: 0.6441\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.6252 - acc: 0.7119\n",
      "Epoch 7\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 37ms/step - loss: 0.5940 - acc: 0.6780\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 0.5930 - acc: 0.7458\n",
      "Epoch 8\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.6218 - acc: 0.6610\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.5488 - acc: 0.7627\n",
      "Epoch 9\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.6202 - acc: 0.6949\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.5943 - acc: 0.6271\n",
      "Epoch 10\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.5549 - acc: 0.6780\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.6193 - acc: 0.5763\n",
      "Epoch 11\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.5754 - acc: 0.6949\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.5407 - acc: 0.7288\n",
      "Epoch 12\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 0.4862 - acc: 0.8136\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.5614 - acc: 0.7627\n",
      "Epoch 13\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.4919 - acc: 0.7627\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.4858 - acc: 0.7627\n",
      "Epoch 14\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.4812 - acc: 0.7797\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.5651 - acc: 0.7119\n",
      "Epoch 15\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.4987 - acc: 0.7797\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.4728 - acc: 0.7627\n",
      "Epoch 16\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.3929 - acc: 0.8475\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.5053 - acc: 0.7458\n",
      "Epoch 17\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 38ms/step - loss: 0.4955 - acc: 0.7288\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.5850 - acc: 0.7288\n",
      "Epoch 18\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 35ms/step - loss: 0.5134 - acc: 0.7119\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 33ms/step - loss: 0.4755 - acc: 0.8136\n",
      "Epoch 19\n",
      "Epoch 1/1\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 0.5440 - acc: 0.7458\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "for e in range(0, 70):\n",
    "    print('Epoch', e)\n",
    "    batches = 0\n",
    "    for X_batch, Y_batch in datagen.flow(X_train, Y_train, batch_size = 59, save_to_dir = 'preview', shuffle = True, save_prefix = 'body', save_format = 'jpg'):\n",
    "        mymodel.fit(X_batch,Y_batch)\n",
    "        batches += 1\n",
    "        if batches >= 2*(X_train.shape[0]/59):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 1)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 224, 224, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv2D)              (None, 54, 54, 50)        6100      \n",
      "_________________________________________________________________\n",
      "bn_0 (BatchNormalization)    (None, 54, 54, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 54, 54, 50)        0         \n",
      "_________________________________________________________________\n",
      "mp_0 (MaxPooling2D)          (None, 26, 26, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 26, 26, 80)        100080    \n",
      "_________________________________________________________________\n",
      "bn_1 (BatchNormalization)    (None, 26, 26, 80)        320       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 26, 26, 80)        0         \n",
      "_________________________________________________________________\n",
      "mp_1 (MaxPooling2D)          (None, 12, 12, 80)        0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 12, 12, 90)        64890     \n",
      "_________________________________________________________________\n",
      "bn_2 (BatchNormalization)    (None, 12, 12, 90)        360       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 12, 90)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 90)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 12, 12, 100)       81100     \n",
      "_________________________________________________________________\n",
      "bn_3 (BatchNormalization)    (None, 12, 12, 100)       400       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 12, 100)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 12, 12, 100)       90100     \n",
      "_________________________________________________________________\n",
      "bn_4 (BatchNormalization)    (None, 12, 12, 100)       400       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 12, 12, 100)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12, 12, 100)       0         \n",
      "_________________________________________________________________\n",
      "mp_2 (MaxPooling2D)          (None, 5, 5, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2500)              0         \n",
      "_________________________________________________________________\n",
      "fc_1 (Dense)                 (None, 100)               250100    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "fc_2 (Dense)                 (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "fc_3 (Dense)                 (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 600,162\n",
      "Trainable params: 599,322\n",
      "Non-trainable params: 840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mymodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "mymodel.fit(X_train, Y_train, epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X1 = []\n",
    "Y1 = []\n",
    "i = 0\n",
    "category = ['Skinny', 'Skinny Fat']\n",
    "for c in category:\n",
    "    path = os.path.join(directory_test, c)\n",
    "    for file in os.listdir(path):\n",
    "        classes = category.index(c)\n",
    "        Y1.append(classes)\n",
    "        img_path = os.path.join(path, file)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_r = cv2.resize(img, (224, 224))\n",
    "        X1.append(img_r)\n",
    "        \n",
    "X_test = np.array(X1)\n",
    "Y_test = np.array(Y1)\n",
    "Y_test = to_categorical(Y_test)\n",
    "cv2.imshow(\"New Image\", X_test[13])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 224, 224, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test.reshape((X_test.shape[0], 224, 224, 1))\n",
    "print(X_test.shape)\n",
    "cv2.imshow(\"New Image\", X_test[13])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    featurewise_center = True,\n",
    "    featurewise_std_normalization = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 26ms/step\n",
      "\n",
      "Loss = 0.8809908552047534\n",
      "Test Accuracy = 0.6923076953643408\n"
     ]
    }
   ],
   "source": [
    "for X_test, Y_test in test_datagen.flow(X_test, Y_test, batch_size = 39, shuffle = True ):\n",
    "    preds = mymodel.evaluate(X_test, Y_test)\n",
    "    print()\n",
    "    print (\"Loss = \" + str(preds[0]))\n",
    "    print (\"Test Accuracy = \" + str(preds[1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 17ms/step\n",
      "\n",
      "Loss = 0.8809908552047534\n",
      "Test Accuracy = 0.6923076953643408\n"
     ]
    }
   ],
   "source": [
    "preds = mymodel.evaluate(X_test, Y_test)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 1)\n",
      "[1. 0.]\n",
      "[[0.9334446  0.06655534]]\n"
     ]
    }
   ],
   "source": [
    "X = X_test[14].reshape((1, 224, 224, 1))\n",
    "\n",
    "print(X.shape)\n",
    "print(Y_test[14])\n",
    "print(mymodel.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = mymodel.to_json()\n",
    "with open(\"mycnn.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    }
   ],
   "source": [
    "mymodel.save_weights(\"mycnn_weights.h5\")\n",
    "print(\"Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
